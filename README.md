# ğŸ§  Refactored DuoFormer
## Multi-Scale Vision Transformer for Medical Imaging

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Quality](https://img.shields.io/badge/code%20quality-A+-success.svg)](docs/CODE_REVIEW_REPORT.md)

**Production-ready, refactored implementation of DuoFormer for general medical image classification with enterprise-grade MLOps practices.**

- ğŸ’¡ **Purpose**:
    - Refactored for general medical imaging use cases including histopathology, radiology, dermatology, and more
- ğŸ”¬ **Original Repository**:
    - [xiaoyatang/duoformer_TCGA](https://github.com/xiaoyatang/duoformer_TCGA)
- ğŸ“„ **Paper**:
    - [Hierarchical Vision Transformer for Medical Image Segmentation (MIDL 2025)](https://arxiv.org/abs/2506.12982)
- ğŸš€ **This Repository**:
    - [AliSerwat/Refactored-DuoFormer](https://github.com/AliSerwat/Refactored-DuoFormer)

---

## âœ¨ What's New in This Enhanced Version

This is a professionally refactored and enhanced version with:

- âœ… **Platform-Independent**: Works on Windows, Linux, macOS
- âœ… **Hardware-Agnostic**: Auto-detects CUDA, MPS (Apple Silicon), or CPU
- âœ… **Modern PyTorch**: No deprecated APIs, latest best practices
- âœ… **MLOps Ready**: Configuration management, auto-checkpointing, TensorBoard
- âœ… **Clean Code**: No wildcard imports, explicit dependencies
- âœ… **Professional Structure**: Modular, testable, maintainable
- âœ… **Comprehensive Testing**: Unit tests and health checks
- âœ… **Auto-Configuration**: Optimal settings for your hardware

---

## ğŸš€ Quick Start

### 1. Installation (30 seconds)

```bash
# 1. Clone repository
git clone https://github.com/AliSerwat/Refactored-DuoFormer.git
cd Refactored-DuoFormer

# One-command setup (handles everything)
python setup_environment.py
```

### 2. Verify Installation

```bash
# Check system capabilities
python scripts/check_system.py

# Verify installation
python scripts/verify_installation.py
```

### 3. Run Demo

```bash
# Interactive notebook
jupyter notebook demo_duoformer.ipynb

# Or platform-agnostic demo
python examples/demo_robust.py
```

### 4. Train Model

```bash
# Auto-configuration (detects your hardware)
python train.py --data_dir /path/to/data

# Or with specific configuration
python train.py --config config/default_config.yaml
```

---

## ğŸ“Š Architecture Overview

**DuoFormer** combines ResNet backbones with multi-scale transformers for medical image classification:

```
Input Image (224Ã—224Ã—3)
    â†“
ResNet Backbone (ResNet-50/18)
    â†“
Multi-Scale Features (2/3/4 scales)
    â†“
Multi-Scale Transformer
    â†“
Classification Head
    â†“
Predictions (num_classes)
```

**Key Features**:
- ğŸ”„ Multi-scale attention at different resolutions
- ğŸ—ï¸ Hybrid CNN-Transformer architecture
- ğŸ¯ Optimized for medical imaging (histopathology, radiology)
- âš¡ Supports 2, 3, or 4 scale levels

---

## ğŸ“ Project Structure

```
refactored-duoformer/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                      Main project documentation (you are here)
â”œâ”€â”€ ğŸ“„ GETTING_STARTED.md             Comprehensive beginner's guide
â”‚
â”œâ”€â”€ ğŸ“ docs/                          Documentation directory
â”‚   â”œâ”€â”€ README.md                     Documentation overview
â”‚   â”œâ”€â”€ INSTALLATION.md               Platform-specific installation
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md            Common issues & solutions
â”‚   â”œâ”€â”€ CONTRIBUTING.md               Development guidelines
â”‚   â”œâ”€â”€ DOCUMENTATION_INDEX.md        Complete documentation map
â”‚   â”œâ”€â”€ CODE_REVIEW_REPORT.md         Code quality analysis
â”‚   â”œâ”€â”€ FIXES_APPLIED.md              What's been fixed
â”‚   â””â”€â”€ QUICK_FIX_REFERENCE.md        Developer quick reference
â”‚
â”œâ”€â”€ ğŸ“ config/                        Configuration Management
â”‚   â”œâ”€â”€ model_config.py               Type-safe configs (Python dataclasses)
â”‚   â”œâ”€â”€ default_config.yaml           Balanced settings
â”‚   â”œâ”€â”€ lightweight_config.yaml       Fast experiments (ResNet-18, 2 scales)
â”‚   â””â”€â”€ performance_config.yaml       Best accuracy (ResNet-50, 4 scales)
â”‚
â”œâ”€â”€ ğŸ“ models/                        Model Architectures
â”‚   â”œâ”€â”€ __init__.py                   Exports: build_model_no_extra_params(), count_parameters()
â”‚   â”œâ”€â”€ model_wo_extra_params.py      Main DuoFormer (recommended)
â”‚   â”œâ”€â”€ model.py                      Original implementation
â”‚   â”œâ”€â”€ multi_vision_transformer.py   Multi-scale transformer
â”‚   â”œâ”€â”€ multiscale_attn.py            Multi-scale attention
â”‚   â”œâ”€â”€ projection_head.py            Projection layers
â”‚   â”œâ”€â”€ resnet50ssl.py                Self-supervised ResNet
â”‚   â””â”€â”€ scale_attention.py            Scale attention mechanisms
â”‚
â”œâ”€â”€ ğŸ“ utils/                         Training Utilities
â”‚   â”œâ”€â”€ trainer.py                    Professional trainer (checkpointing, TensorBoard)
â”‚   â”œâ”€â”€ dataset.py                    MedicalImageDataset, augmentation
â”‚   â”œâ”€â”€ device_utils.py               Auto-detect CUDA/MPS/CPU
â”‚   â””â”€â”€ platform_utils.py             Platform-specific optimizations
â”‚
â”œâ”€â”€ ğŸ“ tests/                         Testing (Resource-Efficient!)
â”‚   â”œâ”€â”€ unit/                         Fast tests (<30s, no GPU)
â”‚   â”œâ”€â”€ integration/                  Full tests (slower, GPU optional)
â”‚   â”œâ”€â”€ fixtures/                     Mock data generators
â”‚   â””â”€â”€ run_tests.py                  Central test runner
â”‚
â”œâ”€â”€ ğŸ“ scripts/                       Utility Scripts
â”‚   â”œâ”€â”€ check_system.py               System capabilities + recommendations
â”‚   â”œâ”€â”€ health_check.py               Code health validation
â”‚   â””â”€â”€ verify_installation.py        Installation verification
â”‚
â”œâ”€â”€ ğŸ“ examples/                      Usage Examples
â”‚   â”œâ”€â”€ demo_robust.py                Platform-agnostic demo
â”‚   â””â”€â”€ example_usage.py              Feature demonstrations
â”‚
â”œâ”€â”€ ğŸ train.py                       Main Training Script
â”œâ”€â”€ ğŸ”§ setup_environment.py           One-Command Setup
â”œâ”€â”€ ğŸ““ demo_duoformer.ipynb           Interactive Demo
â”‚
â”œâ”€â”€ ğŸ“¦ requirements.in                Direct Dependencies
â””â”€â”€ ğŸ“¦ requirements.txt               Lockfile (compiled automatically from requirements.in)
```
---
---

## ğŸ’» Usage

### Training

```bash
# Basic training (auto-configures everything)
python train.py --data_dir /path/to/data

# With custom configuration
python train.py --config config/performance_config.yaml

# Specific device
python train.py --device cuda --data_dir ./data

# Multi-GPU
python train.py --gpu_ids 0,1,2 --data_dir ./data

# CPU only
python train.py --device cpu --batch_size 8 --data_dir ./data

# With mixed precision
python train.py --amp --data_dir ./data

# Resume training
python train.py --resume checkpoints/best_checkpoint.pt
```

### Configuration

```python
from config import ModelConfig

# Load from YAML
config = ModelConfig.from_yaml('config/my_experiment.yaml')

# Or use presets
from config import DEFAULT_CONFIG, LIGHTWEIGHT_CONFIG, PERFORMANCE_CONFIG

# Modify and save
config.training.epochs = 200
config.to_yaml('config/my_custom.yaml')
```

### Inference

```python
import torch
from models import build_model_no_extra_params

# Load checkpoint
checkpoint = torch.load('checkpoints/best_checkpoint.pt')

# Create model
model = build_model_no_extra_params(
    depth=12,
    embed_dim=768,
    num_heads=12,
    num_classes=10,
    num_layers=2,
    backbone='r50'
)

# Load weights
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Predict
with torch.no_grad():
    output = model(image_tensor)
    prediction = output.argmax(dim=1)
```

---

## ğŸ”§ Configuration Options

### Pre-configured Profiles

| Profile | Backbone | Scales | Params | Speed | Use Case |
|---------|----------|--------|--------|-------|----------|
| `lightweight_config.yaml` | ResNet-18 | 2 | ~30M | Fast | Quick experiments |
| `default_config.yaml` | ResNet-50 | 2 | ~50M | Medium | Standard training |
| `performance_config.yaml` | ResNet-50 | 4 | ~70M | Slow | Best accuracy |

### Custom Configuration

Create `config/my_experiment.yaml`:

```yaml
exp_name: my_tcga_experiment
device: auto  # Auto-detects CUDA/MPS/CPU

backbone:
  name: resnet50
  pretrained: true
  freeze: true

transformer:
  depth: 12
  embed_dim: 768
  num_heads: 12

multiscale:
  num_layers: 2
  proj_dim: 768

training:
  learning_rate: 0.0001
  epochs: 100
  batch_size: 32
  optimizer: adamw
  scheduler: cosine

data:
  data_dir: ./data
  num_classes: 10
  image_size: 224
```

Then train:
```bash
python train.py --config config/my_experiment.yaml
```

---

## ğŸŒ Cross-Platform Support

### Automatic Hardware Detection

The codebase automatically detects and optimizes for your platform:

**Windows**:
- Auto-detects CUDA or falls back to CPU
- Optimized `num_workers=4`
- `pin_memory=False` (prevents crashes)

**Linux**:
- Multi-GPU support
- Optimized `num_workers=8`
- `pin_memory=True` (faster transfer)

**macOS**:
- Apple Silicon (M1/M2/M3) MPS support
- Optimized `num_workers=4`
- Automatic device selection

### Device Options

```bash
# Auto-detect (recommended)
python train.py --device auto

# Specific GPU
python train.py --device cuda:0

# Apple Silicon
python train.py --device mps

# CPU only
python train.py --device cpu

# Multi-GPU
python train.py --gpu_ids 0,1,2
```

---

## ğŸ“š Key Features

### 1. **Professional Training Pipeline**

```python
from utils import Trainer

trainer = Trainer(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    device=device,
    use_amp=True,  # Mixed precision
    gradient_clip_val=1.0
)

trainer.fit(
    train_loader,
    val_loader,
    epochs=100,
    patience=20  # Early stopping
)
```

Features:
- âœ… Automatic checkpointing (best, latest, periodic)
- âœ… Early stopping
- âœ… Mixed precision training (AMP)
- âœ… Gradient clipping
- âœ… TensorBoard logging
- âœ… Learning rate scheduling

### 2. **Flexible Dataset Management**

```python
from utils import create_dataloaders

# From directory structure
train_loader, val_loader, test_loader = create_dataloaders(
    data_dir='./data',
    batch_size=32
)

# From CSV file
train_loader, val_loader, test_loader = create_dataloaders(
    csv_file='data.csv',
    batch_size=32
)
```

### 3. **Hardware Optimization**

```python
from utils import setup_device_environment, get_optimal_num_workers

# Auto-detect best device
device = setup_device_environment('auto')

# Get optimal workers for your platform
num_workers = get_optimal_num_workers()
```

---

## ğŸ§ª Testing

```bash
# Fast unit tests (recommended, <30 seconds, no GPU)
python tests/run_tests.py --unit

# Full test suite (all tests)
python tests/run_tests.py

# Integration tests only (slower, may use GPU)
python tests/run_tests.py --integration

# Specific test file
python tests/unit/test_config.py
python tests/integration/test_full_models.py

# With pytest
pytest tests/unit/ -v              # Fast tests only
pytest tests/integration/ -v       # Integration tests
pytest tests/ -v                   # All tests

# Check code health
python scripts/health_check.py
```

---

## ğŸ“¦ Requirements

### System Requirements

- **Python**: 3.8+ (3.10+ recommended)
- **RAM**: 8GB+ (16GB+ recommended)
- **GPU**: Optional (NVIDIA CUDA, or Apple MPS)
- **Storage**: 5GB free space

### Python Dependencies

Managed via `pip-tools` for reproducibility:
- PyTorch 2.0+
- torchvision
- timm (Vision Transformers)
- einops, numpy, matplotlib
- scikit-learn, pandas
- TensorBoard, Jupyter

**Install all**:
```bash
python setup_environment.py
```

---

## ğŸ“– Documentation

- **Quick Start**: This README
- **Getting Started Guide**: See `GETTING_STARTED.md` for detailed walkthrough
- **Installation Guide**: See `docs/INSTALLATION.md` for platform-specific setup
- **Troubleshooting**: See `docs/TROUBLESHOOTING.md` for common issues
- **Contributing**: See `docs/CONTRIBUTING.md` for development guidelines
- **Full Documentation**: See `docs/` directory for complete guides
- **System Check**: `python scripts/check_system.py`
- **Examples**: See `examples/` directory

---

## ğŸ¯ Use Cases

### General Medical Image Classification

This refactored version works with various medical imaging modalities:

```python
# Histopathology (e.g., TCGA, CAMELYON)
python train.py \
    --data_dir ./data/histopathology \
    --num_classes 10 \
    --config config/default_config.yaml

# Radiology (e.g., X-rays, CT, MRI)
python train.py \
    --data_dir ./data/radiology \
    --num_classes 5 \
    --backbone r50 \
    --num_layers 4

# Dermatology (e.g., skin lesions)
python train.py \
    --data_dir ./data/dermatology \
    --num_classes 7 \
    --image_size 224

# Retinal imaging (e.g., diabetic retinopathy)
python train.py \
    --data_dir ./data/retinal \
    --num_classes 5 \
    --config config/performance_config.yaml
```

### Fine-Tuning

```python
# Freeze backbone for faster convergence
python train.py \
    --freeze_backbone \
    --lr 1e-5 \
    --epochs 50 \
    --data_dir ./data
```

---

## ğŸ”¬ Citation

If you use this code, please cite the original paper:

```bibtex
@inproceedings{tang2025duoformer,
  title={DuoFormer: Hierarchical Vision Transformer for Medical Image Segmentation},
  author={Tang, Xiaoya and others},
  booktitle={Medical Imaging with Deep Learning (MIDL)},
  year={2025}
}
```

---

## ğŸ¤ Contributing

Contributions welcome! This enhanced version adds:
- Modern PyTorch APIs
- Platform independence
- MLOps best practices
- Professional structure

See examples/ for usage patterns.

---

## ğŸ“œ License

Same license as original repository.

---

## ğŸ™ Acknowledgments

- **Original Work**: [xiaoyatang/duoformer_TCGA](https://github.com/xiaoyatang/duoformer_TCGA) - Original TCGA-focused implementation
- **Paper**: Tang, X. et al. "Hierarchical Vision Transformer for Medical Image Segmentation" (MIDL 2025)
- **This Refactoring**: Enhanced for general medical imaging with production-ready MLOps practices

---

## ğŸ“ Support

- **System Issues**: `python scripts/check_system.py`
- **Code Health**: `python scripts/health_check.py`
- **Examples**: See `examples/` directory

**Note**: This is a refactored version for general medical imaging. For the original TCGA-specific implementation, see [xiaoyatang/duoformer_TCGA](https://github.com/xiaoyatang/duoformer_TCGA)

---

## â­ Features Comparison

| Feature | Original | Enhanced |
|---------|----------|----------|
| **Code Quality** | Wildcards, deprecated | Explicit, modern âœ… |
| **Platform** | Linux-only paths | Cross-platform âœ… |
| **Device** | Hardcoded CUDA | Auto-detect âœ… |
| **Configuration** | Hardcoded | YAML/JSON âœ… |
| **Training** | Basic loop | Professional trainer âœ… |
| **Monitoring** | Print | TensorBoard âœ… |
| **Testing** | None | Unit tests âœ… |
| **Dependencies** | Manual | pip-tools lockfile âœ… |

---

<div align="center">

**Made with â¤ï¸ for the medical AI community**

[Original Paper](https://arxiv.org/abs/2506.12982) â€¢ [Original Repository](https://github.com/xiaoyatang/duoformer_TCGA)

</div>

