# ğŸš€ Getting Started with Refactored DuoFormer

Welcome! This guide will walk you through the **Refactored DuoFormer** codebase for general medical image classification.

---

## ğŸ“‹ Quick Navigation

- [What is This?](#what-is-this)
- [5-Minute Quickstart](#5-minute-quickstart)
- [Project Structure](#project-structure)
- [Key Features](#key-features)
- [Common Tasks](#common-tasks)
- [FAQ](#faq)

---

## ğŸ¯ What is This?

**Refactored DuoFormer** is a production-ready implementation of a multi-scale vision transformer for **general medical image classification**.

### Supports Multiple Medical Imaging Modalities:
- ğŸ”¬ **Histopathology**: H&E, IHC, whole slide images
- ğŸ¥ **Radiology**: X-ray, CT, MRI, ultrasound
- ğŸ¨ **Dermatology**: Skin lesions, dermoscopy
- ğŸ‘ï¸ **Ophthalmology**: Retinal images, OCT, fundus photography
- ğŸ§¬ **Pathology**: Cell classification, tissue analysis

### Key Enhancements:
âœ… Platform-independent (Windows/Linux/macOS)
âœ… Hardware-agnostic (auto-detects CUDA/MPS/CPU)
âœ… Modern PyTorch (no deprecated APIs)
âœ… Professional MLOps practices
âœ… Clean, modular structure
âœ… Resource-efficient testing

> **Based on**: [xiaoyatang/duoformer_TCGA](https://github.com/xiaoyatang/duoformer_TCGA)
> **Paper**: [arXiv:2506.12982](https://arxiv.org/abs/2506.12982)

---

## âš¡ 5-Minute Quickstart

```bash
# 1. Clone repository
git clone https://github.com/AliSerwat/Refactored-DuoFormer.git
cd Refactored-DuoFormer

# 2. Install dependencies (one command!)
python setup_environment.py

# 3. Check your system
python scripts/check_system.py

# 4. Run quick tests
python tests/run_tests.py --unit

# 5. Try the demo
jupyter notebook demo_duoformer.ipynb
```

**That's it!** You're ready to train on your medical images.

---

## ğŸ“ Project Structure

```
refactored-duoformer/
â”‚
â”œâ”€â”€ ğŸ“ config/                    Configuration Management
â”‚   â”œâ”€â”€ model_config.py              Type-safe configs (Python dataclasses)
â”‚   â”œâ”€â”€ default_config.yaml          Balanced settings
â”‚   â”œâ”€â”€ lightweight_config.yaml      Fast experiments (ResNet-18, 2 scales)
â”‚   â””â”€â”€ performance_config.yaml      Best accuracy (ResNet-50, 4 scales)
â”‚
â”œâ”€â”€ ğŸ“ models/                    Model Architectures
â”‚   â”œâ”€â”€ __init__.py                  Exports: build_model_no_extra_params(), count_parameters()
â”‚   â”œâ”€â”€ model_wo_extra_params.py     Main DuoFormer (recommended)
â”‚   â”œâ”€â”€ model.py                     Original implementation
â”‚   â”œâ”€â”€ multi_vision_transformer.py  Multi-scale transformer
â”‚   â”œâ”€â”€ multiscale_attn.py           Multi-scale attention
â”‚   â”œâ”€â”€ projection_head.py           Projection layers
â”‚   â”œâ”€â”€ resnet50ssl.py               Self-supervised ResNet
â”‚   â””â”€â”€ scale_attention.py           Scale attention mechanisms
â”‚
â”œâ”€â”€ ğŸ“ utils/                     Training Utilities
â”‚   â”œâ”€â”€ trainer.py                   Professional trainer (checkpointing, TensorBoard)
â”‚   â”œâ”€â”€ dataset.py                   MedicalImageDataset, augmentation
â”‚   â”œâ”€â”€ device_utils.py              Auto-detect CUDA/MPS/CPU
â”‚   â””â”€â”€ platform_utils.py            Platform-specific optimizations
â”‚
â”œâ”€â”€ ğŸ“ tests/                     Testing (Resource-Efficient!)
â”‚   â”œâ”€â”€ unit/                        Fast tests (<30s, no GPU)
â”‚   â”œâ”€â”€ integration/                 Full tests (slower, GPU optional)
â”‚   â”œâ”€â”€ fixtures/                    Mock data generators
â”‚   â””â”€â”€ run_tests.py                 Central test runner
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   Utility Scripts
â”‚   â”œâ”€â”€ check_system.py              System capabilities + recommendations
â”‚   â”œâ”€â”€ health_check.py              Code health validation
â”‚   â””â”€â”€ verify_installation.py      Installation verification
â”‚
â”œâ”€â”€ ğŸ“ examples/                  Usage Examples
â”‚   â”œâ”€â”€ demo_robust.py               Platform-agnostic demo
â”‚   â””â”€â”€ example_usage.py             Feature demonstrations
â”‚
â”œâ”€â”€ ğŸ train.py                   Main Training Script
â”œâ”€â”€ ğŸ”§ setup_environment.py       One-Command Setup
â”œâ”€â”€ ğŸ““ demo_duoformer.ipynb       Interactive Demo
â”‚
â”œâ”€â”€ ğŸ“¦ requirements.in            Direct Dependencies
â””â”€â”€ ğŸ“¦ requirements.txt           Lockfile (compiled automatically from requirements.in)
```

---

## âœ¨ Key Features

### 1. **Automatic Hardware Detection**

The codebase automatically detects your hardware and optimizes:

```bash
# Just run with --device auto (default)
python train.py --data_dir ./data

# Automatically detects and uses:
# - CUDA (NVIDIA GPUs)
# - MPS (Apple Silicon M1/M2/M3)
# - CPU (fallback)
```

### 2. **Platform-Specific Optimization**

**Windows**:
- `num_workers=4` (optimal for Windows)
- `pin_memory=False` (prevents crashes)

**Linux**:
- `num_workers=8` (full multi-process)
- `pin_memory=True` (faster GPU transfer)
- `persistent_workers=True`

**macOS**:
- MPS support for Apple Silicon
- Optimized worker count

### 3. **Flexible Dataset Loading**

Two ways to load your data:

**Option A - Directory Structure:**
```
data/
â”œâ”€â”€ class_0/
â”‚   â”œâ”€â”€ image1.png
â”‚   â””â”€â”€ image2.png
â”œâ”€â”€ class_1/
â”‚   â””â”€â”€ ...
```

**Option B - CSV File:**
```csv
image_path,label
/path/to/image1.png,0
/path/to/image2.png,1
```

Both work automatically!

### 4. **Professional Training Pipeline**

```python
from utils import Trainer

trainer = Trainer(model, criterion, optimizer, device)
trainer.fit(train_loader, val_loader, epochs=100)

# Automatically handles:
# âœ“ Checkpointing (best, latest, periodic)
# âœ“ Early stopping
# âœ“ TensorBoard logging
# âœ“ Mixed precision (AMP)
# âœ“ Gradient clipping
```

### 5. **Resource-Efficient Testing**

```bash
# Fast unit tests (30 seconds, no GPU)
python tests/run_tests.py --unit

# Full integration tests (when needed)
python tests/run_tests.py --integration
```

---

## ğŸ“š Common Tasks

### Task 1: Train on Your Medical Images

```bash
# Organize your data (Option A - folders)
# data/
#   â”œâ”€â”€ benign/
#   â””â”€â”€ malignant/

# Train with auto-configuration
python train.py --data_dir ./data --num_classes 2

# Or use a config file
python train.py --config config/default_config.yaml
```

### Task 2: Fine-Tune on Small Dataset

```bash
# Use lightweight config + frozen backbone
python train.py \
    --config config/lightweight_config.yaml \
    --freeze_backbone \
    --lr 1e-5 \
    --epochs 50
```

### Task 3: Train on Specific GPU

```bash
# Single GPU
python train.py --device cuda:0 --data_dir ./data

# Multiple GPUs
python train.py --gpu_ids 0,1,2 --data_dir ./data
```

### Task 4: CPU-Only Training

```bash
python train.py --device cpu --batch_size 8 --data_dir ./data
```

### Task 5: Monitor Training

```bash
# Start TensorBoard (in separate terminal)
tensorboard --logdir=runs

# Open http://localhost:6006 in browser
```

### Task 6: Resume Training

```bash
python train.py --resume checkpoints/best_checkpoint.pt
```

### Task 7: Inference on New Images

```python
import torch
from models import build_model_no_extra_params

# Load checkpoint
checkpoint = torch.load('checkpoints/best_checkpoint.pt')

# Build model
model = build_model_no_extra_params(
    depth=12, embed_dim=768, num_heads=12,
    num_classes=10, num_layers=2, backbone='r50'
)

# Load weights
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Predict
with torch.no_grad():
    output = model(image_tensor)
    prediction = output.argmax(dim=1)
```

---

## ğŸ“ Understanding the Architecture

### Model Components

```
Input Image (224Ã—224Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ResNet Backbone         â”‚ Extract features at multiple scales
â”‚ (ResNet-50/18)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Multi-Scale Features    â”‚ 2, 3, or 4 resolution scales
â”‚ (from different layers) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Multi-Scale Transformer â”‚ Attention across scales
â”‚ (DuoFormer core)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Head     â”‚ Final predictions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (num_classes)
```

### Configuration Profiles

| Profile | Backbone | Scales | Speed | Accuracy | Use When |
|---------|----------|--------|-------|----------|----------|
| **Lightweight** | ResNet-18 | 2 | Fast | Good | Quick experiments |
| **Default** | ResNet-50 | 2 | Medium | Better | Standard training |
| **Performance** | ResNet-50 | 4 | Slow | Best | Maximum accuracy |

---

## ğŸ”§ Customization

### Modify Configuration

Edit `config/my_experiment.yaml`:

```yaml
exp_name: my_experiment
device: auto  # Auto-detect hardware

backbone:
  name: resnet50
  pretrained: true
  freeze: true  # Faster convergence

transformer:
  depth: 12
  embed_dim: 768
  num_heads: 12

multiscale:
  num_layers: 2  # 2, 3, or 4 scales

training:
  learning_rate: 0.0001
  epochs: 100
  batch_size: 32  # Adjust based on GPU memory

data:
  data_dir: ./my_data
  num_classes: 5  # Your number of classes
  image_size: 224
```

Then train:
```bash
python train.py --config config/my_experiment.yaml
```

---

## â“ FAQ

### Q: Which configuration should I use?

**A**: Start with `lightweight_config.yaml` for testing, then use `default_config.yaml` for real training.

### Q: My GPU runs out of memory?

**A**: Reduce batch size:
```bash
python train.py --batch_size 16  # or 8
```

Or use gradient accumulation (coming soon).

### Q: Can I use this without a GPU?

**A**: Yes! Use CPU mode:
```bash
python train.py --device cpu --batch_size 8
```

### Q: What image formats are supported?

**A**: PNG, JPG, JPEG, TIF, TIFF

### Q: How do I add data augmentation?

**A**: It's automatic! Controlled in config:
```yaml
data:
  use_augmentation: true
  random_flip: true
  random_rotation: 10
  color_jitter: true
```

### Q: How do I check if my installation works?

**A**:
```bash
python scripts/verify_installation.py
python scripts/check_system.py
python tests/run_tests.py --unit
```

---

## ğŸ“– Next Steps

1. âœ… **Installation**: `python setup_environment.py`
2. âœ… **Verification**: `python scripts/verify_installation.py`
3. âœ… **System Check**: `python scripts/check_system.py`
4. âœ… **Quick Test**: `python tests/run_tests.py --unit`
5. âœ… **Try Demo**: `jupyter notebook demo_duoformer.ipynb`
6. âœ… **Train Model**: `python train.py --data_dir ./your_data`

---

## ğŸ“š Additional Documentation

- **[Installation Guide](docs/INSTALLATION.md)** - Platform-specific setup instructions
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - Common issues and solutions
- **[Contributing](docs/CONTRIBUTING.md)** - Development guidelines
- **[Code Review](docs/CODE_REVIEW_REPORT.md)** - Code quality analysis
- **[Documentation Index](docs/DOCUMENTATION_INDEX.md)** - Complete documentation map

---

## ğŸ“ Support

- **Check System**: `python scripts/check_system.py`
- **Health Check**: `python scripts/health_check.py`
- **Troubleshooting**: See `docs/TROUBLESHOOTING.md`
- **Examples**: See `examples/` directory
- **Original Paper**: [arXiv:2506.12982](https://arxiv.org/abs/2506.12982)

---

**Happy Training!** ğŸ‰

